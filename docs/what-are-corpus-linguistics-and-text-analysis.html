<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Week 1 What are Corpus Linguistics and Text Analysis? | SLAT7829 Text Analysis and Corpus Linguistics</title>
  <meta name="description" content="Week 1 What are Corpus Linguistics and Text Analysis? | SLAT7829 Text Analysis and Corpus Linguistics" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Week 1 What are Corpus Linguistics and Text Analysis? | SLAT7829 Text Analysis and Corpus Linguistics" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Week 1 What are Corpus Linguistics and Text Analysis? | SLAT7829 Text Analysis and Corpus Linguistics" />
  
  
  

<meta name="author" content="Martin Schweinberger" />


<meta name="date" content="2023-02-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="how-to-design-and-build-a-corpus.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SLAT7829</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#basic-course-information"><i class="fa fa-check"></i>Basic Course Information</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i>Course Description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-introduction"><i class="fa fa-check"></i>Course Introduction</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-staff"><i class="fa fa-check"></i>Course Staff</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#timetable"><i class="fa fa-check"></i>Timetable</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#aims-objectives-graduate-attributes"><i class="fa fa-check"></i>Aims, Objectives &amp; Graduate Attributes</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-aims"><i class="fa fa-check"></i>Course Aims</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-resources"><i class="fa fa-check"></i>Learning Resources</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#required-resources"><i class="fa fa-check"></i>Required Resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recommended-resources"><i class="fa fa-check"></i>Recommended Resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#university-learning-resources"><i class="fa fa-check"></i>University Learning Resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#school-of-languages-and-cultures-learning-resources"><i class="fa fa-check"></i>School of Languages and Cultures Learning Resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#other-learning-resources-information"><i class="fa fa-check"></i>Other Learning Resources &amp; Information</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#teaching-learning-activities"><i class="fa fa-check"></i>Teaching &amp; Learning Activities</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-activities"><i class="fa fa-check"></i>Learning Activities</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-plan"><i class="fa fa-check"></i>Course plan</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#other-teaching-and-learning-activities-information"><i class="fa fa-check"></i>Other Teaching and Learning Activities Information</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html"><i class="fa fa-check"></i><b>1</b> What are Corpus Linguistics and Text Analysis?</a>
<ul>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#what-is-the-difference-between-corpus-linguistics-and-text-analysis"><i class="fa fa-check"></i>What is the difference between corpus linguistics and text analysis?</a></li>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#why-use-corpus-linguistics-cl-or-text-analysis-ta"><i class="fa fa-check"></i>Why use Corpus Linguistics (CL) or Text Analysis (TA)?</a></li>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#why-is-corpus-linguistics-becoming-ever-more-popular-in-research-focusin-on-language-learning-and-teaching"><i class="fa fa-check"></i>Why is corpus linguistics becoming ever more popular in research focusin on language learning and teaching?</a></li>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#basic-concepts-in-corpus-linguistics-and-text-analysis"><i class="fa fa-check"></i>Basic Concepts in Corpus Linguistics and Text Analysis</a></li>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#text-analysis-at-uq"><i class="fa fa-check"></i>Text Analysis at UQ</a></li>
<li class="chapter" data-level="" data-path="what-are-corpus-linguistics-and-text-analysis.html"><a href="what-are-corpus-linguistics-and-text-analysis.html#tools-versus-scripts"><i class="fa fa-check"></i>Tools versus Scripts</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="how-to-design-and-build-a-corpus.html"><a href="how-to-design-and-build-a-corpus.html"><i class="fa fa-check"></i><b>2</b> How to design and build a corpus?</a>
<ul>
<li class="chapter" data-level="" data-path="how-to-design-and-build-a-corpus.html"><a href="how-to-design-and-build-a-corpus.html#things-too-consider-when-compiling-a-corpus"><i class="fa fa-check"></i>Things too consider when compiling a corpus</a></li>
<li class="chapter" data-level="" data-path="how-to-design-and-build-a-corpus.html"><a href="how-to-design-and-build-a-corpus.html#metadata-and-speaker-information"><i class="fa fa-check"></i>Metadata and speaker information</a></li>
<li class="chapter" data-level="" data-path="how-to-design-and-build-a-corpus.html"><a href="how-to-design-and-build-a-corpus.html#what-do-corpora-look-like"><i class="fa fa-check"></i>What do corpora “look” like?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-antconc.html"><a href="introduction-to-antconc.html"><i class="fa fa-check"></i><b>3</b> Introduction to AntConc</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-antconc.html"><a href="introduction-to-antconc.html#what-is-antconc"><i class="fa fa-check"></i>What is AntConc?</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SLAT7829 Text Analysis and Corpus Linguistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="what-are-corpus-linguistics-and-text-analysis" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Week 1</span> What are Corpus Linguistics and Text Analysis?<a href="what-are-corpus-linguistics-and-text-analysis.html#what-are-corpus-linguistics-and-text-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This tutorial introduces Corpus Linguistics <span class="citation">(see <a href="#ref-r2022handboocl" role="doc-biblioref">O’Keeffe and McCarthy 2022</a>; <a href="#ref-gries2009whatiscorpuslinguistics" role="doc-biblioref">S. Th. Gries 2009</a>; <a href="#ref-biber1998corpus" role="doc-biblioref">Biber, Conrad, and Reppen 1998</a>; <a href="#ref-gries2009quantitative" role="doc-biblioref">S. T. Gries 2009</a>)</span>, i.e., the study of language through the analysis of large collections of text (corpora), and Text Analysis <span class="citation">(see <a href="#ref-bernard1998text" role="doc-biblioref">Bernard and Ryan 1998</a>; <a href="#ref-kabanoff1997introduction" role="doc-biblioref">Kabanoff 1997</a>; <a href="#ref-popping2000computer" role="doc-biblioref">Popping 2000</a>)</span>, i.e. computer-based analysis of language data or the (semi-)automated extraction of information from text.</p>
<p><strong>Corpus linguistics</strong> is a research methodology that involves the systematic analysis of large collections of natural language data, known as corpora. Corpus linguistics is based on the idea that language can be best understood by analyzing large, representative samples of naturally occurring language use. Corpora can be compiled from a variety of sources, including written texts, spoken language, and even online communication. Through the use of computational tools and statistical methods, corpus linguistics enables researchers to identify patterns and relationships within language use, providing insights into linguistic phenomena such as grammar, vocabulary, and discourse.</p>
<p><strong>Text Analysis</strong> is associated with a divers set of computational methods that enable researchers to explore text and analyse unstructured data, i.e., text (unstructured is used here in contrast to structured, i.e., tabular data). Due to the increasing availability of large amounts of textual data, text analytics methods and distant reading techniques are becoming more and more important and relevant to a larger body of researchers and disciplines.</p>
<p>This tutorial introduces basic concepts of Corpus Linguistics Text Analysis (also referred to as Distant Reading). The aim is not to provide a fully-fledged analysis but rather to discuss and explore selected useful methods associated with text analysis and distant reading.</p>
<div id="what-is-the-difference-between-corpus-linguistics-and-text-analysis" class="section level2 unnumbered hasAnchor">
<h2>What is the difference between corpus linguistics and text analysis?<a href="what-are-corpus-linguistics-and-text-analysis.html#what-is-the-difference-between-corpus-linguistics-and-text-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Text analysis and corpus linguistics are related but distinct fields.</p>
<p>Text analysis is a broad term that refers to any systematic process of examining text, whether it be a single document or a collection of documents, in order to gain insights into its content, meaning, or other characteristics. Text analysis can involve various methods and techniques, such as content analysis, discourse analysis, and sentiment analysis.</p>
<p>Corpus linguistics, on the other hand, is a specific subfield of linguistics that uses large collections of texts, called corpora, as the basis for linguistic analysis. Corpus linguistics involves the use of computational tools and statistical methods to analyze linguistic patterns and relationships within a corpus.</p>
<p>While both text analysis and corpus linguistics involve the systematic examination of texts, corpus linguistics is more focused on the quantitative analysis of large, representative samples of language use, whereas text analysis can encompass a broader range of qualitative and quantitative methods for analyzing text.</p>
</div>
<div id="why-use-corpus-linguistics-cl-or-text-analysis-ta" class="section level2 unnumbered hasAnchor">
<h2>Why use Corpus Linguistics (CL) or Text Analysis (TA)?<a href="what-are-corpus-linguistics-and-text-analysis.html#why-use-corpus-linguistics-cl-or-text-analysis-ta" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Since both CL and TA extract and analyse information from textual data, they can be considered a derivative of computational linguistics or an application of <em>Natural Language Processing</em> (NLP). As such, CL and TA represent the application of computational methods in the humanities and thus falls within computational humanities research.</p>
<p>The advantages of CL and TA include:</p>
<ul>
<li><p>Extraction of information from large textual data sets</p></li>
<li><p>Replicability and reproducibility of analyses</p></li>
</ul>
<p>What is relevant to consider here is that CL and TA contrasts with traditional armchair linguistics or close-reading techniques which do not employ computational means of exploring and analyzing texts. CL and TA, while allowing for qualitative analysis, builds upon quantitative information, i.e. information about frequencies or conditional probabilities.</p>
<p>Armchair linguistics refers to the analysis of language through introspection and it differs from CL in that CL uses (large) amounts of data to arrive at an understanding how language works.</p>
</div>
<div id="why-is-corpus-linguistics-becoming-ever-more-popular-in-research-focusin-on-language-learning-and-teaching" class="section level2 unnumbered hasAnchor">
<h2>Why is corpus linguistics becoming ever more popular in research focusin on language learning and teaching?<a href="what-are-corpus-linguistics-and-text-analysis.html#why-is-corpus-linguistics-becoming-ever-more-popular-in-research-focusin-on-language-learning-and-teaching" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Corpus linguistics has become increasingly popular in language learning and teaching research for several reasons.</p>
<ol style="list-style-type: decimal">
<li>Corpora provide a large and diverse set of authentic language data, which can be used to develop and evaluate language learning and teaching materials and methods. Corpus-based research can help identify patterns of language use, highlight common errors, and reveal areas of difficulty for language learners.<br />
</li>
<li>Corpus linguistics offers a more systematic and objective way of analyzing language data than traditional approaches to language analysis. By using computational tools and statistical methods, researchers can identify patterns and relationships within language use that may not be immediately apparent through traditional methods of language analysis.<br />
</li>
<li>Corpus linguistics can help bridge the gap between theory and practice in language learning and teaching. By providing empirical evidence of how language is actually used in real-world contexts, corpus-based research can inform language pedagogy and curriculum design, helping to ensure that language teaching is grounded in sound linguistic principles and is effective in helping learners achieve their language learning goals.</li>
</ol>
<p>Overall, corpus linguistics has proven to be a valuable tool for language learning and teaching research, providing a rich and reliable source of data that can be used to improve language pedagogy and better understand how language is used in real-world contexts.</p>
<p>*Why is Ditant Reading becoming ever more popular in the humanities?**</p>
<p>Distant Reading is a cover term for applications of TA that allow to investigate literary and cultural trends by analyzing large amounts of textual data. close reading refers to reading texts in the traditional sense. Text Analysis and distant reading are similar with respect to the methods that are used but with different outlooks. The outlook of distant reading is to extract information from text without close reading, i.e. reading the document(s) itself but rather focusing on emerging patterns in the language that is used.</p>
<p><img src="https://slcladal.github.io/images/GoogleNgram.png" width="60%" style="float:right; padding:10px" /></p>
<p>Text Analysis is rapidly gaining popularity in the humanities because textual data is readily available and because computational methods can be applied to a huge variety of research questions. The attractiveness of computational text analysis based on digitally available texts and in their capability to provide insights that cannot be derived from close reading techniques.</p>
<p>While there are some nuances, Text Mining, Text Analytics, and Distant Reading are more or less synonymous with Text Analysis. Regarding these minor differences, Text Analysis is commonly considered more qualitative while Text Analytics is considered to be quantitative. In contrast to Text Analysis, Text Mining is often more data-driven and usually applies methods without substantive supervision or assistance from the human researcher. Distant Reading is used mostly when dealing with literary or academic texts while Text Mining is associated with social media or more generally Big Data. In the following, we use Text Analysis as a cover term encompassing Text Mining, Text Analytics, and Distant Reading.</p>
<p><img src="https://slcladal.github.io/images/romeonet.png" width="40%" style="float:right; padding:10px" /></p>
<p>While rapidly growing as a valid approach to analyzing textual data, Text Analysis is <a href="https://www.chronicle.com/article/The-Digital-Humanities-Debacle/245986">critizised</a> for lack of “quantitative rigor and because its findings are either banal or, if interesting, not statistically robust (see <a href="https://www.chronicle.com/article/The-Digital-Humanities-Debacle/245986">here</a>. This criticism is correct in that most of the analysis that performed in <em>Computational Literary Studies</em> (CLS) are not yet as rigorous as analyses in fields that have a longer history of computational based, quantitative research, such as, for instance, corpus linguistics. However, the practices and methods used in CLS will be refined, adapted and show a rapid increase in quality if more research is devoted to these approaches. Text Analysis simply offers an alternative way to analyze texts that is not in competition to traditional techniques but rather complements them.</p>
<p>So far, most of the applications of Text Analysis are based upon a relatively limited number of key procedures or concepts (e.g. concordancing, word frequencies, annotation or tagging, parsing, collocation, text classification, Sentiment Analysis, Entity Extraction, Topic Modeling, etc.). In the following, we will explore these procedures and introduce some basic tools that help you perform the introduced tasks.</p>
</div>
<div id="basic-concepts-in-corpus-linguistics-and-text-analysis" class="section level2 unnumbered hasAnchor">
<h2>Basic Concepts in Corpus Linguistics and Text Analysis<a href="what-are-corpus-linguistics-and-text-analysis.html#basic-concepts-in-corpus-linguistics-and-text-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This session introduces basic concepts in corpus linguistics and text analysis.</p>
<p><strong>Glossary of Important Concepts</strong></p>
<p>Below, you will find explanations of concepts and methods that are important in Text Analysis and also links to relevant resources (including LADAL tutorials).</p>
<p><strong>Word</strong></p>
<p>What a word is is actually very tricky. For instance, How many words are there in this sentence?</p>
<blockquote>
<p>The cat sat on the mat
One answer is that there are six words; that is, there are six <em>groups of characters</em> which are separated according to typographical convention. But there is another answer: There are five words, that is five <em>distinct sequences</em> of characters and one of those sequences (the) occurs twice. The terms commonly used to make this distinction are <strong>type</strong> and <strong>token</strong>. Tokens are instances of types, therefore if we count tokens, we count without considering repetition, while if we count types, we do consider repetition. In our example, there are five types (the, cat, sat, on, mat) but six tokens, because there are two tokens of one of the types (the).</p>
</blockquote>
<p>There is a further distinction we may need to make which we can see if we consider another question: are <em>cat</em> and <em>cats</em> the same word? They are distinct types, and therefore must also be distinct as tokens. But we have an intuition that at some level they are related, that there is some more abstract item which underlies both of them. This concept is usually referred to as a <strong>lemma</strong>.</p>
<p><img src="https://slcladal.github.io/images/AntConcConcordance.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Concordancing</strong></p>
<p>In Text Analysis, concordancing refers to the extraction of words from a given text or texts <span class="citation">(<a href="#ref-lindquist2009corpus" role="doc-biblioref">Lindquist 2009</a>)</span>. Commonly, concordances are displayed in the form of key-word in contexts (KWIC) where the search term is shown with some preceding and following context. Thus, such displays are referred to as key word in context concordances. A more elaborate tutorial on how to perform concordancing with R is available <a href="https://slcladal.github.io/kwics.html">here</a>. If you do not want to use coding to extract concordances, a highly recommendable tool for extracting concordances (and many other TA tasks) is <a href="https://www.laurenceanthony.net/software/antconc/">AntConc</a>.</p>
<p>Concordancing is helpful for seeing how the term is used in the data, for inspecting how often a given word occurs in a text or a collection of texts, for extracting examples, and it also represents a basic procedure and often the first step in more sophisticated analyses of language data.</p>
<p><strong>Corpus (pl. Corpora)</strong></p>
<p>A corpus is a machine readable and electronically stored collection of natural language texts representing writing or speech chosen to be characteristic of a variety or the state of a language <span class="citation">(see <a href="#ref-sinclair1991corpus" role="doc-biblioref"><strong>sinclair1991corpus?</strong></a>)</span>. Corpora are great for extracting examples of natural examples and testing research hypotheses as it is easy to obtain information on frequencies, grammatical patterns, or collocations and they are commonly publicly available so the research results can be contrasted, compared and repeated.</p>
<p>There are four main types of corpora:</p>
<ul>
<li><strong>Text corpora</strong>: These are collections of written texts that are used to study written language. Text corpora can include books, newspapers, magazines, and other written materials (e.g., the <em>Corpus of Historical American English</em>, COHA).<br />
</li>
<li><strong>Spoken corpora</strong>: These are collections of spoken language that are used to study oral language. Spoken corpora can include recordings of conversations, speeches, interviews, and other spoken interactions (e.g., the <em>Australian Radio Talkback</em> corpus).<br />
</li>
<li><strong>Parallel corpora</strong>: These are collections of texts or spoken language that are translated into multiple languages. Parallel corpora are used to study translation and language transfer (e.g., the <em>Europarl Corpus</em>).<br />
</li>
<li><strong>Multimodal corpora</strong>: These are collections of language data that include multiple modes of communication, such as spoken language, written language, images, and videos (e.g., <em>British National Corpus</em>, BNC).<br />
</li>
<li><strong>Diachronic corpora</strong>: These are collections of language data that span a long period of time. Diachronic corpora are used to study language change over time (e.g., the Penn-Helsinki Parsed Corpus of Early Modern English).<br />
</li>
<li><strong>Synchronic corpora</strong>: These are collections of language data that are collected at a particular point in time. Synchronic corpora are used to study language variation and language use in a particular community or context (e.g., the <em>Corpus of Contemporary American English</em>, COCA).<br />
</li>
<li><strong>Specialized corpora</strong>: These are collections of language data that focus on a particular domain or topic, such as medical language, legal language, or scientific language (e.g., the <em>Child Language Data Exchange System</em>, CHILDES).<br />
</li>
<li><strong>Online corpora</strong>: Online corpora are collections of language data that are available for access and search on the internet (e.g., the <em>Corpus of Contemporary American English</em>, COCA).</li>
</ul>
<p><img src="https://slcladal.github.io/images/collocates.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Collocations</strong></p>
<p>Collocations are words that are attracted to each other (and that co-occur or co-locate together), e.g., <em>Merry Christmas</em>, <em>Good Morning</em>, <em>No worries</em>, or <em>Fuck off</em>. Collocations are important because any word in any given language has collocations, i.e., others words that are attracted to that word or words that that word is attracted to
allow us to anticipate what word comes next and collocations are context/text type specific. It is important to note that collocations to not have to appear/occur right next to each other but that other words can be in between. There are various different statistical measures are used to define the strength of the collocations, like the Mutual Information (MI) score and log-likelihood (<a href="http://www.collocations.de/AM/index.html">see here for an over view of different association strengths measures</a>).</p>
<p><strong>Document Classification</strong></p>
<p>Document or Text Classification (also referred to as text categorization) generally refers to process of grouping texts or documents based on similarity. This similarity can be based on word frequencies or other linguistics features but also on text external features such as genre labels or polarity scores.</p>
<p><strong>Document-Term Matrix</strong></p>
<p>Document-Term Matrices (DTM) and Term- Document Matrices (TDM) contain the frequencies of words per document. DTM and TDM differ in whether the words or the documents are represented as rows. Thus, the words (terms) are listed as row names and the documents represent the column names while the matrix itself contains the frequencies of the words in the documents.</p>
<p><img src="https://slcladal.github.io/images/speciescloud.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Frequency Analysis</strong></p>
<p>Frequency Analysis is a suit of methods which extract and compare frequencies of different words (tokens and/or types), collocations, phrases, sentences, etc. These frequencies are the often tabulated to show lists of words, phrases, etc. descending by frequency, visualized to show distributions, and/or compared and analyzed statistically to find differences between texts or collections fo texts.</p>
<p><strong>Keyword Analysis</strong></p>
<p>Keyword Analysis refers to a suit of methods that allow to detect words that are characteristic of on text or collection of texts compared to another text/collection of texts. There are various keyness measures such as Log-Likelihood or the term frequency–inverse document frequency (tf-idf).</p>
<p><strong>Lemma (Lemmatization)</strong></p>
<p>Lemma refers to the base form of a word (example: <em>walk</em>, <em>walked</em>, and <em>walking</em> are word forms of the lemma <em>WALK</em>). Lemmatization refers to a annotation process in which word forms are associated with their base form (lemma). Lemmatization is a very common and sometimes useful processing step for further analyses. In contrast to stemming - which is a related process - lemmatization also takes into account semantic differences (differences in the word meaning), while stemming only takes the orthography of words into consideration.</p>
<p><strong>N-Gram</strong></p>
<p>N-grams are combinations/sequences of words, e.g. the sentence <em>I really like pizza!</em> has the bi-grams (2-grams): <em>I really</em>, <em>really like</em>, and <em>like pizza</em> and the tri-grams (3-grams) <em>I really like</em> and <em>really like pizza</em>. N-grams play an important part in natural language processing (e.g. part-of-speech tagging), language learning, psycholinguistics models of language production, and genre analysis.</p>
<p><strong>Natural Language Processing</strong></p>
<p>Natural Language Processing (NLP) is an interdisciplinary field in computer science that has specialized on processing natural language data using computational and mathematical methods. Many methods used in Text Analysis have been developed in NLP.</p>
<p><img src="https://slcladal.github.io/images/romeonet.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Network Analysis</strong></p>
<p>Network Analysis is the most common way to visualize relationships between entities. Networks, also called graphs, consist of nodes (typically represented as dots) and edges (typically represented as lines) and they can be directed or undirected networks.</p>
<p>In directed networks, the direction of edges is captured. For instance, the exports of countries. In such cases the lines are directed and typically have arrows to indicate direction. The thickness of lines can also be utilized to encode information such as frequency of contact.</p>
<p><strong>Part-of-Speech Tagging</strong></p>
<p>Part-of-Speech (PoS) Tagging identifies the word classes of words (e.g., noun, adjective, verb, etc.) in a text and adds part-of-speech tags to each word. There are various part-of-speech tagsets, e.g. the Penn Treebank is the most frequently used tagset used for English. A more detailed tutorial on how to perform part-of-speech tagging in R can be found <a href="https://slcladal.github.io/tagging.html">here</a>.</p>
<p><strong>Project Gutenberg</strong></p>
<p>The Project Gutenberg is a excellent resource for accessing digitized literary texts. The Project Gutenberg library contains over 60,000 ebooks that are out of copyright in the US. A tutorial on how to download texts form the Project Gutenberg library using the <code>GutenbergR</code> package can be found <a href="https://slcladal.github.io/gutenberg.html">here</a>.</p>
<p><strong>Regular Expression</strong></p>
<p>Regular Expressions - often simply referred to as regex - are symbols or sequence of symbols utilized to search for patterns in textual data. Regular Expressions are very useful and widely used in Text Analysis and often different programming languages will have very similar but slightly different Regular Expressions. A tutorial on how to use regular expression in R can be found <a href="https://slcladal.github.io/regex.html">here</a> and here is a link to a <a href="https://raw.githubusercontent.com/rstudio/cheatsheets/main/regex.pdf">regex in R cheat sheet</a>.</p>
<p><strong>Semantic Analysis</strong></p>
<p>Semantic Analysis refers to a suit of methods that allow to analyze the semantic (semantics) fo texts. Such analyses often rely on semantic tagsets that are based on word meaning or meaning families/categories. Two examples of such semantic tagsets are the <a href="https://ucrel.lancs.ac.uk/claws7tags.html">URCEL tagset</a> and the <a href="http://eprints.gla.ac.uk/115024/"><em>Historical Thesaurus Semantic Tagger</em></a> <span class="citation">(<a href="#ref-alexander2015tagger" role="doc-biblioref"><strong>alexander2015tagger?</strong></a>)</span> developed at the University of Glasgow.</p>
<p><img src="https://slcladal.github.io/images/senti.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Sentiment Analysis</strong></p>
<p>Sentiment Analysis is a computational approach to determine if words or texts are associated with (positive or negative) polarity or emotions.Commonly, sentiments analyses are based on sentiment dictionaries (words are annotated based on whether they occur in a list of words associated with, e.g., positive polarity or emotion, e.g., <em>fear</em>, <em>anger</em>, or <em>joy.</em> A tutorial on how to perform sentiment analysis in R can be found <a href="https://slcladal.github.io/sentiment.html">here</a>.</p>
<p><strong>String</strong></p>
<p>In computational approaches, a string is a specific type of data that represents text and is often encoded in specific format, e.g., Latin1 or UTF8. Strings may also be present in other data types such as lists or data frames. A tutorial on how to work with strings in R can be found <a href="https://slcladal.github.io/string.html">here</a>.</p>
<p><strong>Term Frequency–Inverse Document Frequency (tf-idf)</strong></p>
<p>Term Frequency–Inverse Document Frequency is a statistical measure of keyness which reflects how characteristic a word is of a specific text. Term Frequency–Inverse Document Frequency is based on the frequencies of words in a text compared to the frequency of documents in which it occurs</p>
<p><img src="https://slcladal.github.io/images/topic.png" width="40%" style="float:right; padding:10px" /></p>
<p><strong>Topic Modeling</strong></p>
<p>Topic modelling is a machine learning method seeks to answer the question: given a collection of documents, can we identify what they are <em>about</em>?</p>
<p>Topic model algorithms look for patterns of co-occurrences of words in documents. We assume that, if a document is about a certain topic, one would expect words that are related to that topic to appear in the document more often than in documents that deal with other topics. Topic model commonly use Latent Dirichlet Allocation (LDA) to find <em>topics</em> in textual data.</p>
<p>There are two basic types of Topic models</p>
<ul>
<li><p>supervised or seeded topics models where the researchers provides seed terms around which the LDS looks for topics (collections of correlating terms)</p></li>
<li><p>unsupervised or unseeded topic models which try to find a predefined number of topics (collections of correlating terms)</p></li>
</ul>
<p>A tutorial on how to work with strings in R can be found <a href="https://slcladal.github.io/topicmodels.html">here</a>.</p>
</div>
<div id="text-analysis-at-uq" class="section level2 unnumbered hasAnchor">
<h2>Text Analysis at UQ<a href="what-are-corpus-linguistics-and-text-analysis.html#text-analysis-at-uq" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As LADAL has been established at The University of Queensland, we have listed selected resources on Text Analysis offered by UQ.</p>
<p>The <a href="https://www.library.uq.edu.au/">UQ Library</a> offers a very handy and attractive summary of <a href="https://guides.library.uq.edu.au/research-techniques/text-mining-analysis/introduction">resources, concepts, and tools</a> that can be used by researchers interested in Text Analysis and Distant Reading. Also, the UQ library site offers short video introductions and addresses issues that are not discussed here such as <a href="https://guides.library.uq.edu.au/research-techniques/text-mining-analysis/considerations">copyright issues</a>, <a href="https://guides.library.uq.edu.au/research-techniques/text-mining-analysis/sources-of-text-data">data sources available at the UQ library</a>, as well as <a href="https://guides.library.uq.edu.au/research-techniques/text-mining-analysis/sources-of-text-data">social media</a> and <a href="https://guides.library.uq.edu.au/research-techniques/text-mining-analysis/web-scraping">web scaping</a>.</p>
<p>In contrast to the UQ library site, the focus of this introduction lies on the practical how-to of text analysis. this means that the following concentrates on how to perform analyses rather than discussing their underlying concepts or evaluating their scientific merits.</p>
</div>
<div id="tools-versus-scripts" class="section level2 unnumbered hasAnchor">
<h2>Tools versus Scripts<a href="what-are-corpus-linguistics-and-text-analysis.html#tools-versus-scripts" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is perfectly fine to use tools for the analyses exemplified below. However, the aim of <a href="ladal.edu.au">LADAL</a> is not primarily to show how to perform text analyses but how to perform text analyses in a way that complies with practices that guarantee sustainable, transparent, reproducible research. As R code can be readily shared and optimally contains all the data extraction, processing, visualization, and analysis steps, using scripts is preferable over using (commercial) software.</p>
<p>In addition to being not as transparent and hindering reproduction of research, using tools can also lead to dependencies on third parties which does not arise when using open source software.</p>
<p>Finally, the widespread use of R particularly among data scientists, engineers, and analysts reduces the risk of software errors as a very active community corrects flawed functions typically quite rapidly.</p>
<p><img src="https://slcladal.github.io/images/netta.png" width="40%" style="float:right; padding:10px" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bernard1998text" class="csl-entry">
Bernard, H Russell, and Gery Ryan. 1998. <span>“Text Analysis.”</span> <em>Handbook of Methods in Cultural Anthropology</em> 613.
</div>
<div id="ref-biber1998corpus" class="csl-entry">
Biber, Douglas, Susan Conrad, and Randi Reppen. 1998. <em>Corpus Linguistics: Investigating Language Structure and Use</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-gries2009quantitative" class="csl-entry">
Gries, Stefan Th. 2009. <em>Quantitative Corpus Linguistics with r: A Practical Introduction</em>. Routledge.
</div>
<div id="ref-gries2009whatiscorpuslinguistics" class="csl-entry">
Gries, Stefan Th. 2009. <span>“What Is Corpus Linguistics?”</span> <em>Language and Linguistics Compass</em> 3: 1–17.
</div>
<div id="ref-kabanoff1997introduction" class="csl-entry">
Kabanoff, Boris. 1997. <span>“Introduction: Computers Can Read as Well as Count: Computer-Aided Text Analysis in Organizational Research.”</span> <em>Journal of Organizational Behavior</em>, 507–11.
</div>
<div id="ref-lindquist2009corpus" class="csl-entry">
Lindquist, Hans. 2009. <em>Corpus Linguistics and the Description of English</em>. Edinburgh: Edinburgh University Press.
</div>
<div id="ref-r2022handboocl" class="csl-entry">
O’Keeffe, Anne, and Michael McCarthy. 2022. <em>The Routledge Handbook of Corpus Linguistics</em>. 2nd ed. London: Routledge.
</div>
<div id="ref-popping2000computer" class="csl-entry">
Popping, Roel. 2000. <em>Computer-Assisted Text Analysis</em>. Sage.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="how-to-design-and-build-a-corpus.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/MartinSchweinberger/SLAT7829/edit/master/01-Intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/MartinSchweinberger/SLAT7829/blob/master/01-Intro.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
